{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMWMOaDg-ZBv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "text = Path(\"../../../data/tiny-shakespeare.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IwwOe-tJ-xcE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap_Ixr0M-0Yv"
   },
   "outputs": [],
   "source": [
    "class CharTokenizer:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.token_id_for_char = {\n",
    "            char: token_id for token_id, char in enumerate(vocabulary)\n",
    "        }\n",
    "        self.char_for_token_id = {\n",
    "            token_id: char for token_id, char in enumerate(vocabulary)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def train_from_text(text):\n",
    "        vocabulary = set(text)\n",
    "        return CharTokenizer(sorted(list(vocabulary)))\n",
    "\n",
    "    def encode(self, text):\n",
    "        token_ids = []\n",
    "        for char in text:\n",
    "            token_ids.append(self.token_id_for_char[char])\n",
    "        return torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        chars = []\n",
    "        for token_id in token_ids.tolist():\n",
    "            chars.append(self.char_for_token_id[token_id])\n",
    "        return \"\".join(chars)\n",
    "\n",
    "    def vocabulary_size(self):\n",
    "        return len(self.token_id_for_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3q9Dj3l-2Ja"
   },
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer.train_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb1zImZr-4mY"
   },
   "outputs": [],
   "source": [
    "print(tokenizer.encode(\"Hello world\"))\n",
    "print(tokenizer.decode(tokenizer.encode(\"Hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlTEiIqs-7Uz"
   },
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {tokenizer.vocabulary_size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Qal76ig-94U"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TokenIdsDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, pos):\n",
    "        assert pos < len(self.data) - self.block_size\n",
    "\n",
    "        x = self.data[pos : pos + self.block_size]\n",
    "        y = self.data[pos + 1 : pos + 1 + self.block_size]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPPfQ5n1_BuV"
   },
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.encode(text)\n",
    "dataset = TokenIdsDataset(tokenized_text, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pU5xPNPN_RSQ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "sampler = RandomSampler(dataset, replacement=True)\n",
    "dataloader = DataLoader(dataset, batch_size=2, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmoIkxKP_gBD"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKvdaDFb_mxv"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRYTdaFs_nrH"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7z-wrmxL_ucH"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-programming-in-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
