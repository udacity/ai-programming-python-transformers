{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "cb3pFfQJ5g9K",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hgI1So37iYz"
   },
   "source": [
    "## Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_LNmCOI5w-s"
   },
   "outputs": [],
   "source": [
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpyOFeER55ic"
   },
   "outputs": [],
   "source": [
    "# From HuggingFace docs: https://huggingface.co/docs/hub/index\n",
    "text = \"\"\"\n",
    "The Hub is home to over 5,000 datasets in more than 100 languages that can be used for a broad range of tasks across NLP, Computer Vision, and Audio. The Hub makes it simple to find, download, and upload datasets.\n",
    "Datasets are accompanied by extensive documentation in the form of Dataset Cards and Dataset Preview to let you explore the data directly in your browser.\n",
    "While many datasets are public, organizations and individuals can create private datasets to comply with licensing or privacy issues. You can learn more about Datasets here on Hugging Face Hub documentation.\n",
    "\n",
    "The ðŸ¤— datasets library allows you to programmatically interact with the datasets, so you can easily use datasets from the Hub in your projects.\n",
    "With a single line of code, you can access the datasets; even if they are so large they donâ€™t fit in your computer, you can use streaming to efficiently access the data.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarizer(text, max_length=130, min_length=30)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEwEfpCu6rmJ"
   },
   "outputs": [],
   "source": [
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5WD2ZVK72YY"
   },
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMV8RjV271iA"
   },
   "outputs": [],
   "source": [
    "# Load the text generation pipeline\n",
    "generator = pipeline(\"text-generation\")\n",
    "\n",
    "# Define the prompt for the text generation\n",
    "prompt = \"Scientists from University of California, Berkeley has announced that\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "generated_text = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnrKcoB_7JFy"
   },
   "outputs": [],
   "source": [
    "generated_text[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLUjNVLx94kq"
   },
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iofyHYf9980Q"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# From here\n",
    "text = \"Transformers support framework interoperability between PyTorch, TensorFlow, and JAX. This provides the flexibility to use a different framework at each stage of a modelâ€™s life; train a model in three lines of code in one framework, and load it for inference in another.\"\n",
    "\n",
    "labels = [\"technology\", \"biology\", \"space\", \"transport\"]\n",
    "\n",
    "results = classifier(text, candidate_labels=labels, hypothesis_template=\"This text is about {}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "599bvZt2-end"
   },
   "outputs": [],
   "source": [
    "for label, score in zip(results['labels'], results['scores']):\n",
    "  print(f\"{label} -> {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXNyKrl7ljpe"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Replace the URL below with the URL of your image\n",
    "image_url = 'https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png'\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oS96nMAN9f6J"
   },
   "outputs": [],
   "source": [
    "captioner = pipeline(model=\"ydshieh/vit-gpt2-coco-en\")\n",
    "\n",
    "result = captioner(\"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ag0FIqLmTCf"
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
